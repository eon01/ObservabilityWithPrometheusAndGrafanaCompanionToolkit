# Monitoring Kubernetes with Prometheus


## Kubernetes Service Discovery for Prometheus


```yaml
scrape_configs:
  - job_name: "kubernetes-pods"

    kubernetes_sd_configs:
      - role: pod

    relabel_configs:
      # Map all Kubernetes pod labels to Prometheus labels
      - action: labelmap
        regex: __meta_kubernetes_pod_label_(.+)

      # Replace the 'namespace' label with the value from Kubernetes namespace metadata
      - source_labels: [__meta_kubernetes_namespace]
        target_label: namespace

      # Replace the 'pod' label with the value from Kubernetes pod name metadata
      - source_labels: [__meta_kubernetes_pod_name]
        target_label: pod
```


```yaml
scrape_configs:
  - job_name: "kubernetes-nodes"

    kubernetes_sd_configs:
      - role: node

    relabel_configs:
      # Map all Kubernetes node labels to Prometheus labels
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)

      # Replace the 'node' label with the value from Kubernetes node name metadata
      - source_labels: [__meta_kubernetes_node_name]
        target_label: node

      # Replace the 'provider' label with the value from Kubernetes node provider metadata
      - source_labels: [__meta_kubernetes_node_provider_id]
        target_label: provider
```


## Creating a Kubernetes Cluster


```bash
cat <<EOF >> ~/.bashrc && source ~/.bashrc
export NODE1IP=10.135.0.19
export NODE2IP=10.135.0.9
export NODE3IP=10.135.0.2
EOF
```


```bash
declare -a IPS=($NODE1IP $NODE2IP $NODE3IP)
```


```bash
ssh-keygen -t rsa -b 4096
```


```bash
# Configure the Ansible environment
mkdir -p /root/ansible/ && cat <<EOF > /root/ansible/anisble.cfg
[ssh_connection]
# Enables pipelining to reduce the number of SSH operations.
pipelining=True

# SSH argument settings.
# Reuses SSH connections for multiple tasks, 
# keeps connection open for 30 minutes after last use,
# makes 100 connection attempts before failing, 
# and ignores SSH key checking.
ssh_args = -o ControlMaster=auto \
-o ControlPersist=30m \
-o ConnectionAttempts=100 \
-o UserKnownHostsFile=/dev/null

# Default settings for Ansible.
[defaults]

# Disables SSH host key checking.
host_key_checking=False          

# Gathers facts only when needed.
gathering = smart                

# Caches facts in JSON format.
fact_caching = jsonfile          

# Location where facts are cached.
fact_caching_connection = /tmp   

# Modifies the output format.
stdout_callback = skippy         

# Lists callbacks that are enabled.
callback_whitelist = profile_tasks 

# Disables deprecation warnings.
deprecation_warnings=False 
EOF

# Install Python 3.9
sudo add-apt-repository ppa:deadsnakes/ppa -y
sudo apt update
sudo apt install python3.9 -y
apt install python3.9-distutils -y

# Install "pip3"
apt install python3-pip -y

# Install "virtualenv" and "virtualenvwrapper"
sudo apt install virtualenvwrapper -y
mkdir -p ~/.virtualenvs

# Add the following lines to the "~/.bashrc" file
cat <<EOF >> ~/.bashrc
export WORKON_HOME=~/.virtualenvs
export VIRTUALENVWRAPPER_PYTHON=/usr/bin/python3
source /usr/share/virtualenvwrapper/virtualenvwrapper.sh
EOF

# Reload the "~/.bashrc" file
source ~/.bashrc

# Create a virtual environment for Kubespray
mkvirtualenv -p python3.9 kubespray

# Download the Kubespray repository
git clone https://github.com/kubernetes-incubator/kubespray.git
cd kubespray
git checkout v2.24.1

# Copy the inventory dir to "mycluster" instead of using the sample directory
cp -rfp inventory/sample inventory/mycluster

# Install the dependencies from the "requirements.txt" file:
pip install -r requirements.txt

# We will use Ansible Core 2.15.8 
pip install ansible-core==2.15.8

# Create an inventory
CONFIG_FILE=inventory/mycluster/hosts.yml \
python3 contrib/inventory_builder/inventory.py \
${IPS[@]}
```


```yaml
all:
  hosts:
    node1:
      ansible_host: x.x.x.x
      ip: x.x.x.x
      access_ip: x.x.x.x
    node2:
      ansible_host: x.x.x.x
      ip: x.x.x.x
      access_ip: x.x.x.x
    node3:
      ansible_host: x.x.x.x
      ip: x.x.x.x
      access_ip: x.x.x.x
  children:
    kube_control_plane:
      hosts:
        node1:
        node2:
    kube_node:
      hosts:
        node1:
        node2:
        node3:
    etcd:
      hosts:
        node1:
        node2:
        node3:
    k8s_cluster:
      children:
        kube_control_plane:
        kube_node:
    calico_rr:
      hosts: {}
```


```bash
CONFIG_FILE=inventory/mycluster/hosts.yml \
python3 contrib/inventory_builder/inventory.py \
${IPS[@]}
```


```bash
ansible -i inventory/mycluster/hosts.yml -m ping all
```


```bash
export PRIVATE_KEY="/root/.ssh/id_rsa"
```


```bash
ansible-playbook \
  -i inventory/mycluster/hosts.yml \
  -v \
  --become \
  --become-user=root \
  --private-key=$PRIVATE_KEY \
  cluster.yml
```


```bash
# Copy the "admin.conf" file to the control node
mkdir -p ~/.kube && scp \
  root@$NODE1IP:/etc/kubernetes/admin.conf \
  ~/.kube/config

# Install the `kubectl` tool (always on the control node)
cd "$(mktemp -d /tmp/kubectl-XXX)"
version="1.30.0"
url="https://storage.googleapis.com/kubernetes-release/release/v${version}/bin/linux/amd64/kubectl"
curl --silent --location --fail --remote-name "${url}"
chmod +x ./kubectl
mv ./kubectl /usr/local/bin/kubectl
kubectl version --client

# Add the completion script to your .bashrc file
echo 'source <(kubectl completion bash)' >>~/.bashrc
source ~/.bashrc
```


```bash
sed -i "s/127.0.0.1/$NODE1IP/g" ~/.kube/config
```


```bash
kubectl get nodes
```


## Exporters and Metrics in Kubernetes


```bash
kubectl proxy --port=8001
```


```bash
# change me to the master node name
export NODE1NAME="node1"

# "/proxy/metrics"
curl http://127.0.0.1:8001/api/v1/nodes/$NODE1NAME/proxy/metrics

# "/proxy/metrics/cadvisor"
curl http://127.0.0.1:8001/api/v1/nodes/$NODE1NAME/proxy/metrics/cadvisor

# "/proxy/metrics/resource"
curl http://127.0.0.1:8001/api/v1/nodes/$NODE1NAME/proxy/metrics/resource

# "/proxy/metrics/probes"
curl http://127.0.0.1:8001/api/v1/nodes/$NODE1NAME/proxy/metrics/probes
```


```bash
# Install Helm
curl -fsSL -o \
    get_helm.sh \
    https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3    
chmod 700 get_helm.sh
./get_helm.sh

# Add the Prometheus Helm repository
helm repo add \
    prometheus-community \
    https://prometheus-community.github.io/helm-charts

# Update the Helm repositories
helm repo update

# Install the Node Exporter
helm upgrade --install \
    node-exporter \
    prometheus-community/prometheus-node-exporter
```


```bash
kubectl port-forward \
    svc/node-exporter-prometheus-node-exporter \
    -n default \
    9100:9100
```


```bash
# Node exporter default port is 9100
curl http://127.0.0.1:9100/metrics
```


```bash
# Add the Prometheus Helm repository
helm repo add \
    prometheus-community \
    https://prometheus-community.github.io/helm-charts

# Update the Helm repositories
helm repo update

# Install the kube-state-metrics exporter
helm upgrade --install \
    kube-state-metrics \
    prometheus-community/kube-state-metrics
```


```bash
kubectl port-forward \
    svc/kube-state-metrics \
    -n default \
    8080:8080
```


```bash
curl http://127.0.0.1:8080/metrics
```


## Kubernetes Metrics Endpoints



### General Kubelet Metrics (/metrics)


### Container and System Metrics (/metrics/cadvisor)


### Pod and Node Resource Utilization (/metrics/resource)


### Kubelet Probes Monitoring (/metrics/probes)


### Comprehensive Kubelet Metrics (/stats/summary)


### Node Exporter Metrics



### kube-state-metrics


## Monitoring Kubernetes with Prometheus; a Practical Example


```bash
kubectl create ns hello-world
kubectl -n hello-world \
  create deployment hello-world \
  --replicas=2 \
  --image=k8s.gcr.io/echoserver:1.4
```


```bash
# Filter by namespace
kube_pod_status_phase{namespace="hello-world"}

# Filter by pod
kube_pod_status_phase{pod="hello-world-xxxxx-xxxxx"}
```


```bash
# Add the Prometheus Helm repository
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts

# Update the Helm repositories
helm repo update
```


```yaml
cat <<EOF > values.yaml
server:
  persistentVolume:
    # Disable persistent volume for the sake of simplicity
    # Should be enabled in production
    enabled: false

kube-state-metrics:
  ## If false, kube-state-metrics sub-chart will not be installed
  enabled: true    

serverFiles:
  prometheus.yml:
     # Add our testing job to the Prometheus configuration
     scrape_configs:
      - job_name: "hello-world"
        # Do not change labels
        honor_labels: true
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:          
          # Map all Kubernetes pod labels to Prometheus labels
          - action: labelmap                
            regex: __meta_kubernetes_pod_label_(.+)
          # Replace the 'namespace' label 
          # with the value from Kubernetes namespace metadata
          - action: replace
            source_labels: [__meta_kubernetes_namespace]            
            target_label: namespace
          # Replace the 'pod' label 
          # with the value from Kubernetes pod name metadata
          - action: replace
            source_labels: [__meta_kubernetes_pod_name]            
            target_label: pod              
EOF
```


```bash
# Install Prometheus
helm upgrade \
  --install \
  prometheus \
  prometheus-community/prometheus \
  -f values.yaml
```


```bash
export POD_NAME=$(kubectl get pods --namespace default -l "app.kubernetes.io/name=prometheus,app.kubernetes.io/instance=prometheus" -o jsonpath="{.items[0].metadata.name}")
kubectl --namespace default port-forward $POD_NAME 9090
```


```bash
export CONTROL_NODE_IP="your_control_node_ip"
ssh -L 9090:localhost:9090 root@$CONTROL_NODE_IP
```


```bash
# Filter by namespace
kube_pod_status_phase{namespace="hello-world"}

# Filter by pod
kube_pod_status_phase{pod=~"hello-world-.*"}

# Filter by phase
kube_pod_status_phase{phase="Running", namespace="hello-world"}
```